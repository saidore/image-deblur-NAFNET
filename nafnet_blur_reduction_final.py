# -*- coding: utf-8 -*-
"""NAFNET_Blur_Reduction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zFULse9yb_O695m7erc5utBjSW7j-oPo

# **Install Dependencies and Set up Environment**
"""

import torch
torch.cuda.empty_cache()  #Clears cache from gpu
import gc
gc.collect()  #Deletes objects no longer in use

!pip install numpy
!pip install --upgrade pytorch-msssim
!pip install torchvision>=0.15.0
#!pip install lpips
#Installs all needed dependencies
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import torchvision.transforms as transforms
import torchvision.models as models
import cv2
import os
import numpy as np
import pandas as pd
import kagglehub
import sys
from tqdm import tqdm
import torch.nn.functional as F

!git clone https://github.com/pavancm/CONTRIQUE.git

dataset_path = kagglehub.dataset_download("lqzmlaq/gopro-large")  #Downloads GoPro Kaggle dataset
print("Path to dataset files:", dataset_path)

sys.path.append("/content/CONTRIQUE/modules")
from CONTRIQUE_model import CONTRIQUE_model
dataset_path = "/root/.cache/kagglehub/datasets/lqzmlaq/gopro-large/versions/1/GOPRO_Large"  #Adds path to CONTRIQUE model

"""# **Feature Extraction**"""

#Defines paths for train and test folders
train_path = os.path.join(dataset_path, "train")
test_path = os.path.join(dataset_path, "test")

#Checks that train and test directories exist
if not os.path.exists(train_path):
    print(f"Train directory not found at: {train_path}")
if not os.path.exists(test_path):
    print(f"Test directory not found at: {test_path}")

#Function to gather image file paths
def get_image_paths(root_dir):  #Walks through each folder and collects paired blurred and sharp image paths
    blurred_images = []  #Blurred image paths
    sharp_images = []   #Sharp image paths

    for scene_folder in os.listdir(root_dir):  #Lists every item in root directory
        scene_path = os.path.join(root_dir, scene_folder)  #Full path to folder

        if os.path.isdir(scene_path):  #Only proceeds if valid directory
            blurred_dir = os.path.join(scene_path, "blur")  #Blur folder
            sharp_dir = os.path.join(scene_path, "sharp")   #Sharp folder

            if os.path.exists(blurred_dir) and os.path.exists(sharp_dir):  #Ensures blur and sharp folders exist
                for img_name in sorted(os.listdir(blurred_dir)):  #Ensures matching order
                    #Adds full file paths to lists
                    blurred_images.append(os.path.join(blurred_dir, img_name))
                    sharp_images.append(os.path.join(sharp_dir, img_name))

    return blurred_images, sharp_images

#Gets all image paths for training and testing
train_blurred, train_sharp = get_image_paths(train_path)
test_blurred, test_sharp = get_image_paths(test_path)

#Configuration settings, following code created with assistance from ChatGPT and Claude AI
class Args:
    def __init__(self):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.batch_size = 16  #Images processed at once
        self.temperature = 0.5  #Temperature for contrastive loss
        self.world_size = 1  #Number of distributed processes
        self.reload = False  #Whether to load a pre-trained model
        self.model_path = './models'  #Path to saved models
        self.epoch_num = 0  #Starting epoch number
        self.patch_dim= (23,40)  #Dimension for non-overlapping patches

args = Args()
#Initializes ResNet-50 encoder
encoder = models.resnet50(pretrained=True)  #Downloads weights trained on ImageNet
n_features = encoder.fc.in_features  #Number of features in the final layer
encoder = torch.nn.Sequential(*list(encoder.children())[:-1])  #Removes the final classification layer to get raw feature maps

#Loads CONTRIQUE model
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = CONTRIQUE_model(args, encoder, n_features).to(device)
model.eval()  #Model set to evaluation mode

#Image transformation for CONTRIQUE
transform = transforms.Compose([
    transforms.ToTensor(),
])

#Creates non-overlapping patches to reduce memory
def create_patches(img, patch_size=(23, 40)):
    b, c, h, w = img.shape  #Batch size, channels, height and width
    patch_h, patch_w = patch_size  #Patch dimensions

    #Ensures height and width are multiples of patch size, if not image is padded
    if h % patch_h != 0 or w % patch_w != 0:
        img = F.pad(img, (0, patch_w - w % patch_w, 0, patch_h - h % patch_h))

    #Uses unfold to create patches efficiently
    patches = img.unfold(2, patch_h, patch_h).unfold(3, patch_w, patch_w)
    patches = patches.contiguous().view(b, c, -1, patch_h, patch_w)  #Combines patches into single dimension
    patches = patches.permute(2, 0, 1, 3, 4).contiguous()  #Moves patches to first dimension

    return patches

#Function to extract features
def extract_features_batch(image_paths, batch_size, num_batches=3):
    all_features = []  #Aggregate feature vectors

    for i in tqdm(range(0, min(len(image_paths), batch_size * num_batches), batch_size), desc="Extracting Features"): #terates through every batch
        batch_paths = image_paths[i:i + batch_size]
        batch_images = []  #Loaded and transformed images

        for image_path in batch_paths:
            img = cv2.imread(image_path)  #Reads BGR image
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  #Converts image to RGB
            img = cv2.resize(img, (640, 360))  #Resizes input for consistency
            img = transform(img).unsqueeze(0).to(args.device)  #Changes to batch dimensions and converts to tensor
            batch_images.append(img)

        batch_images = torch.cat(batch_images, dim=0)  #Concatenates individual batch tensors to one tensor
        patches = create_patches(batch_images, args.patch_dim).to(args.device)  #Creates non-overlapping patches
        num_patches = patches.shape[0]     #Gets number of patches
        patches = patches.view(-1, patches.shape[2], patches.shape[3], patches.shape[4])  #Flattens patch dimensions

        with torch.no_grad():  #Disables gradient calculation
            features = model(patches,patches)[1].cpu().numpy() #Returns tensor at first index

        features = features.reshape(len(batch_images), num_patches, -1)     #Reshapes features to have the shape (num_images, num_patches, feature_dim)
        aggregated_features = np.mean(features, axis=1)     #Averages features over the patches
        all_features.extend(aggregated_features)  #Adds images' feature vectors

        del batch_images, patches, features  #Clears memory
        torch.cuda.empty_cache()
        gc.collect()

    return all_features  #Feature vectors for processed images

data = []
batch_size = 16
train_blur_features = extract_features_batch(train_blurred, batch_size)  #List of feature vectors for blurred images
train_sharp_features = extract_features_batch(train_sharp, batch_size)   #List of feature vectors for sharp images
#Loops through image pairs and its feature vectors
for blur_path, blur_features, sharp_path, sharp_features in zip(train_blurred, train_blur_features, train_sharp, train_sharp_features):
    data.append({
        "image_name": os.path.basename(blur_path),
        "class": "blurred",
        **{f"feature_{i}": blur_features[i] for i in range(len(blur_features))}
    })  #Creates a record for the blurred image
    data.append({
        "image_name": os.path.basename(sharp_path),
        "class": "sharp",
        **{f"feature_{i}": sharp_features[i] for i in range(len(sharp_features))}
    })  #Creates a record for the sharp image

df = pd.DataFrame(data)
df.to_csv("image_features.csv", index=False)

print("Feature extraction complete! Saved to image_features.csv")

"""# **Dataset Attributes**


"""

#What attributes are highly correlated in the dataset
#Loads the extracted features dataset
file_path = "image_features.csv"
df = pd.read_csv(file_path)
#Selects only feature columns
feature_columns = [col for col in df.columns if "feature_" in col]
#Computes the correlation matrix
correlation_matrix = df[feature_columns].corr()
#Extracts highly correlated feature pairs (absolute correlation > 0.8)
threshold = 0.8
highly_correlated_features = (
    correlation_matrix.where(
        (abs(correlation_matrix) > threshold) & (abs(correlation_matrix) < 1.0)  #Excludes self-correlation
    )
    .stack()
    .reset_index()
)
highly_correlated_features.columns = ["Feature_1", "Feature_2", "Correlation"]

#Removes duplicate pairs (since correlation is symmetric)
highly_correlated_features = highly_correlated_features.loc[
    highly_correlated_features["Feature_1"] < highly_correlated_features["Feature_2"]
]

#Displays top 10 most correlated feature pairs
print(highly_correlated_features.sort_values(by="Correlation", ascending=False))

top_features = set(highly_correlated_features["Feature_1"]).union(set(highly_correlated_features["Feature_2"]))
top_features = list(top_features)
#Extracts a subset of the correlation matrix with only those features
filtered_corr_subset = correlation_matrix.loc[top_features, top_features]
#Plots the confusion matrix-style heatmap
plt.figure(figsize=(10, 8))
ax = sns.heatmap(filtered_corr_subset, annot=True, fmt=".2f", cmap="coolwarm", linewidths=0.5, square=True)

#Formatting the plot to match the style
ax.set_title("Confusion Matrix for Highly Correlated Features")
ax.set_xlabel("Predicted Features")
ax.xaxis.tick_top()
ax.xaxis.set_label_position("top")
ax.set_ylabel("Actual Features")
#Rotates the x-axis labels to prevent overlap
plt.xticks(rotation=45, ha='left', rotation_mode='anchor')
plt.show()

#What attributes have the most variation for each class (blurred vs sharp)?
variance_per_class = df.groupby("class")[feature_columns].var()

#Identifies the top 10 most varying features for each class
most_variable_blurred = variance_per_class.loc["blurred"].sort_values(ascending=False).head(10)
most_variable_sharp = variance_per_class.loc["sharp"].sort_values(ascending=False).head(10)

#Displays results
print("\nTop 10 Most Varying Features (Blurred Images):")
print(most_variable_blurred)

print("\nTop 10 Most Varying Features (Sharp Images):")
print(most_variable_sharp)

#Plots bar chart for most varying features in each class
plt.figure(figsize=(12, 6))

#Bar plot for blurred images
plt.barh(most_variable_blurred.index[::-1], most_variable_blurred.values[::-1], label="Blurred", alpha=0.6)

#Bar plot for sharp images
plt.barh(most_variable_sharp.index[::-1], most_variable_sharp.values[::-1], label="Sharp", alpha=0.6)

#Plot Formatting
plt.xlabel("Variance")
plt.ylabel("Feature")
plt.title("Top 10 Most Varying Features for Blurred vs. Sharp Images")
plt.legend()
plt.grid(axis="x", linestyle="--", alpha=0.7)

#Shows the plot
plt.show()

#What specific attributes can be used to understand the data? i.e. features with high variance (distinguishing info), low correlation redundancy
#(features that aren't highly coorelated with others so they possess unique info), and significant difference between blurred and sharp images
#Computes variance for all features
feature_variance = df[feature_columns].var()

#Computes mean difference between blurred and sharp classes
mean_per_class = df.groupby("class")[feature_columns].mean()
mean_difference = abs(mean_per_class.loc["blurred"] - mean_per_class.loc["sharp"])

#Sets thresholds for selecting useful features
variance_threshold = feature_variance.mean()  #Features with above-average variance
mean_diff_threshold = mean_difference.mean()  #Features with above-average mean difference

#Selects features that meet both criteria
filtered_features  = feature_variance[
    (feature_variance > variance_threshold) & (mean_difference > mean_diff_threshold)
].index.tolist()

to_remove = set()

#If two features are highly coorelated, then one of the features will be removed since they contain redundant information
for feature in filtered_features:
    if feature not in to_remove:
        correlated_features = correlation_matrix[feature][abs(correlation_matrix[feature]) > threshold].index.tolist()
        correlated_features.remove(feature)  #Keep one, removes others
        to_remove.update(correlated_features)

#Final useful features list after removing redundant ones
useful_features = [feat for feat in filtered_features if feat not in to_remove]

print(f"Identified {len(useful_features)} useful features")
print("\nUseful Features:")
print(useful_features)

#What attributes are most confusing in understanding the data (low variance, similar mean vals between blurred and sharp images, highly coorelated with other features)?
#Counts how many times a feature is highly correlated (above 0.8 threshold)
correlation_counts = (abs(correlation_matrix) > threshold).sum() - 1  #Subtracts 1 to exclude self-correlation

#Sets thresholds for defining "confusing" features
low_variance_threshold = feature_variance.mean() / 2  #Features with significantly lower than average variance
low_mean_diff_threshold = mean_difference.mean() / 2  #Features with low mean differences
high_correlation_threshold = correlation_counts.mean()  #Features highly correlated with many others

#Identifies confusing features (meeting at least two of the three conditions)
condition = (
    (feature_variance < low_variance_threshold) & (mean_difference < low_mean_diff_threshold) |
    (feature_variance < low_variance_threshold) & (correlation_counts > high_correlation_threshold) |
    (mean_difference < low_mean_diff_threshold) & (correlation_counts > high_correlation_threshold)
    )
confusing_features = np.array(feature_columns)[np.where(condition)[0]].tolist()

print(f"Identified {len(confusing_features)} confusing features.")
print("\nMost Confusing Features:")
print(confusing_features)

"""# **Data Visualizations**"""

#Visualize the distributions using PCA
from sklearn.decomposition import PCA

#Prepares the feature data and labels
feature_columns = [col for col in df.columns if "feature_" in col]
X = df[feature_columns].values  #Extracts feature values
y = df["class"].values  #Extracts class labels (blurred or sharp)

#Applies PCA to reduce dimensions to 2 for visualization
pca = PCA(n_components=3)
X_pca = pca.fit_transform(X)

#Converts to DataFrame for plotting
pca_df = pd.DataFrame(X_pca, columns=["PC1", "PC2", "PC3"])
pca_df["class"] = y

#Plots PCA scatter plot in 3D
fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection='3d')

#Maps classes to colors
colors = {"blurred": "red", "sharp": "blue"}
scatter = ax.scatter(pca_df["PC1"], pca_df["PC2"], pca_df["PC3"], c=pca_df["class"].map(colors), alpha=0.7)

ax.set_title("PCA Visualization of Blurred vs. Sharp Images")
ax.set_xlabel("Principal Component 1")
ax.set_ylabel("Principal Component 2")
ax.set_zlabel("Principal Component 3")

#Creates a legend
legend_labels = list(colors.keys())
legend_handles = [plt.Line2D([0], [0], marker='o', color='w', label=label, markerfacecolor=colors[label], markersize=10) for label in legend_labels]
ax.legend(handles=legend_handles, title="Image Class")
ax.grid(True)
plt.show()

#Variance explained by each component
explained_variance = pca.explained_variance_ratio_

#Plots explained variance
plt.figure(figsize=(8, 5))
plt.scatter(range(1, 4), explained_variance, marker="o", color="b")
plt.xlabel("Principal Component")
plt.ylabel("Explained Variance Ratio")
plt.title("Explained Variance by Principal Components")

#Shows plot
plt.show()

#Clustering algorithm to help understand the data
from sklearn.mixture import GaussianMixture
from sklearn.preprocessing import StandardScaler
from mpl_toolkits.mplot3d import Axes3D

#Loads the dataset
file_path = "image_features.csv"
df = pd.read_csv(file_path)

#Selects feature columns and labels
X = df[feature_columns].values  #Extracts feature values
y = df["class"].values  #Extracts class labels (blurred vs. sharp)

#Applies Gaussian Mixture Model (GMM) with 2 clusters (expected sharp vs. blurred separation)
gmm = GaussianMixture(n_components=2, random_state=42)
clusters = gmm.fit_predict(X)

#Adds GMM cluster labels to the dataframe
df["gmm_cluster"] = clusters

#Evaluates the clustering results
cluster_vs_class = pd.crosstab(df["gmm_cluster"], df["class"])

#Displays clustering results
print("GMM Cluster vs Actual Class Distribution")
print(cluster_vs_class)

#Checks the number of clusters detected
num_clusters = len(set(clusters))
print(f"Number of clusters detected {num_clusters}")

#Tries GMM with more clusters (k=3, k=4)
for k in [3, 4]:
    gmm_more = GaussianMixture(n_components=k, random_state=42)
    clusters_more = gmm_more.fit_predict(X)
    #Adds new cluster assignments to DataFrame
    df[f"gmm_cluster_{k}"] = clusters_more

    #Prints cluster distribution for new k values
    cluster_vs_class_more = pd.crosstab(df[f"gmm_cluster_{k}"], df["class"])
    print(f"\nGMM Cluster vs Actual Class Distribution (k={k})")
    print(cluster_vs_class_more)

    #Checks number of clusters detected
    num_clusters = len(set(clusters_more))
    print(f"Number of clusters detected: {num_clusters}")

#GMM is used to help understand the data, but it does a somewhat poor job of separating sharp vs blurred images, as neither cluster 0 or 1 favors
#sharp or blurred images. This suggests a signficant overlap between the two classes, meaning that the extracted features don't fully
#differentiate between the two. But compared to K-means and DBSCAN, GMM does a slightly better job with clustering

#There are signnificant overlaps between the clusters as both clusters have a high mix of sharp and blurred images. The feature space does not separate between the two well.

#Experimenting with more clusters (3 and 4) does not lead to improved class separation even with a changed distribution. The blurred and sharp images remain heavily mixed
#in each cluster so regardless of clusters, the feature space does not distinguish well.

#Clustering algorithm to help understand the data
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from mpl_toolkits.mplot3d import Axes3D
import pandas as pd

#Loads the dataset
file_path = "image_features.csv"
df = pd.read_csv(file_path)

#Selects feature columns and labels
feature_columns = [col for col in df.columns if "feature_" in col]
X = df[feature_columns].values  #Extracts feature values
y = df["class"].values  #Extracts class labels (blurred vs. sharp)

#Applies K-Means clustering with 2 clusters (expected sharp vs. blurred separation)
kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)
clusters = kmeans.fit_predict(X)

#Adds K-Means cluster labels to the dataframe
df["kmeans_cluster"] = clusters

#Evaluates the clustering results
cluster_vs_class = pd.crosstab(df["kmeans_cluster"], df["class"])

#Displays clustering results
print("K-Means Cluster vs Actual Class Distribution")
print(cluster_vs_class)

#Checks the number of clusters detected
num_clusters = len(set(clusters))
print(f"Number of clusters detected {num_clusters}")

#Tries K-Means with more clusters (k=3, k=4)
for k in [3, 4]:
    kmeans_more = KMeans(n_clusters=k, random_state=42, n_init=10)
    clusters_more = kmeans_more.fit_predict(X)
    #Adds new cluster assignments to DataFrame
    df[f"kmeans_cluster_{k}"] = clusters_more

    #Prints cluster distribution for new k values
    cluster_vs_class_more = pd.crosstab(df[f"kmeans_cluster_{k}"], df["class"])
    print(f"\nK-Means Cluster vs Actual Class Distribution (k={k})")
    print(cluster_vs_class_more)

    #Checks number of clusters detected
    num_clusters = len(set(clusters_more))
    print(f"Number of clusters detected: {num_clusters}")

#Noise/outlier data within the dataset
from sklearn.ensemble import IsolationForest

#Applies Isolation Forest to detect outliers
iso_forest = IsolationForest(contamination=0.05, random_state=42)
outliers = iso_forest.fit_predict(X)

#Adds outlier labels to the dataframe (-1 indicates an outlier)
df["outlier"] = outliers

#Counts the number of outliers
num_outliers = list(outliers).count(-1)

#Displays the number of outliers detected
print(f"Number of outliers detected: {num_outliers}")

#Displays some examples of detected outliers
outlier_samples = df[df["outlier"] == -1]
print("\nOutlier Data Points:")
print(outlier_samples[["image_name", "class", "outlier"] ])  #Shows first few feature columns for reference

#Displays a pair of blurred and sharp images side by side
def visualize_image_pair(blur_path, sharp_path):
    #Reads the images
    blur_img = cv2.imread(blur_path)
    sharp_img = cv2.imread(sharp_path)

    #Converts from BGR to RGB (matplotlib uses RGB)
    blur_img = cv2.cvtColor(blur_img, cv2.COLOR_BGR2RGB)
    sharp_img = cv2.cvtColor(sharp_img, cv2.COLOR_BGR2RGB)

    #Displays the images side by side
    fig, axes = plt.subplots(1, 2, figsize=(12, 6))

    axes[0].imshow(blur_img)
    axes[0].set_title('Blurred Image')
    axes[0].axis('off')

    axes[1].imshow(sharp_img)
    axes[1].set_title('Sharp Image')
    axes[1].axis('off')

    plt.tight_layout()
    plt.show()

#Visualizes a few random image pairs from the training set
import random

#Selects random indices to visualize
num_samples = 3  #Number of image pairs to visualize
indices = random.sample(range(len(train_blurred)), num_samples)
#Visualizes the random pairs of blurred and sharp images
for idx in indices:
    blur_path = train_blurred[idx]
    sharp_path = train_sharp[idx]
    print(f"Image pair {idx+1}: {os.path.basename(blur_path)}")
    visualize_image_pair(blur_path, sharp_path)

#Visualizes features extracted from a blurred and sharp image pair
def visualize_feature_differences(blur_path, sharp_path, model, device):
    #Loads and process images
    blur_img = cv2.imread(blur_path)
    blur_img = cv2.cvtColor(blur_img, cv2.COLOR_BGR2RGB)  #Converts image to RGB format
    blur_img = cv2.resize(blur_img, (640, 360))  #Resizes to fixed resolution
    blur_tensor = transform(blur_img).unsqueeze(0).to(device)  #Converts image to tensor and adds batch dimensions

    sharp_img = cv2.imread(sharp_path)
    sharp_img = cv2.cvtColor(sharp_img, cv2.COLOR_BGR2RGB)   #Converts image to RGB format
    sharp_img = cv2.resize(sharp_img, (640, 360))   #Resizes to fixed resolution
    sharp_tensor = transform(sharp_img).unsqueeze(0).to(device)  #Converts image to tensor and adds batch dimensions

    #Extracts features
    with torch.no_grad():
        blur_patches = create_patches(blur_tensor, args.patch_dim).to(device)   #Creates patches for blurred image from tensor
        sharp_patches = create_patches(sharp_tensor, args.patch_dim).to(device)   #Creates patches for sharp image from tensor

        num_patches = blur_patches.shape[0]  #Number of patches extracted
        #Flattens patch and batch dimensions
        blur_patches = blur_patches.view(-1, blur_patches.shape[2], blur_patches.shape[3], blur_patches.shape[4])
        sharp_patches = sharp_patches.view(-1, sharp_patches.shape[2], sharp_patches.shape[3], sharp_patches.shape[4])
        #Runs CONTRIQUE model and returns features for images
        blur_features = model(blur_patches, blur_patches)[1].cpu().numpy()
        sharp_features = model(sharp_patches, sharp_patches)[1].cpu().numpy()

    #Displays images and feature comparison
    fig = plt.figure(figsize=(15, 10))

    #Original images
    ax1 = fig.add_subplot(2, 2, 1)
    ax1.imshow(blur_img)
    ax1.set_title('Blurred Image')
    ax1.axis('off')

    ax2 = fig.add_subplot(2, 2, 2)
    ax2.imshow(sharp_img)
    ax2.set_title('Sharp Image')
    ax2.axis('off')

    #Feature visualization (PCA of the first 50 features)
    from sklearn.decomposition import PCA

    #Reshapes features to aggregate over patches
    blur_features = blur_features.reshape(1, num_patches, -1)
    sharp_features = sharp_features.reshape(1, num_patches, -1)

    #Averages over patches
    blur_avg_features = np.mean(blur_features, axis=1)[0]
    sharp_avg_features = np.mean(sharp_features, axis=1)[0]

    #Uses first 50 features for visualization
    feature_subset = 50

    #Feature difference histogram
    ax3 = fig.add_subplot(2, 2, 3)
    feature_diff = sharp_avg_features[:feature_subset] - blur_avg_features[:feature_subset]
    ax3.bar(range(feature_subset), feature_diff)
    ax3.set_title('Feature Differences (Sharp - Blur)')
    ax3.set_xlabel('Feature Index')
    ax3.set_ylabel('Difference')

    #Feature comparison scatter
    ax4 = fig.add_subplot(2, 2, 4)
    ax4.scatter(blur_avg_features[:feature_subset], sharp_avg_features[:feature_subset], alpha=0.7)
    ax4.plot([min(blur_avg_features[:feature_subset]), max(blur_avg_features[:feature_subset])],
             [min(blur_avg_features[:feature_subset]), max(blur_avg_features[:feature_subset])], 'r--')
    ax4.set_title('Feature Comparison (Sharp vs. Blur)')
    ax4.set_xlabel('Blur Features')
    ax4.set_ylabel('Sharp Features')

    plt.tight_layout()
    plt.show()

random_idx = random.randint(0, len(train_blurred) - 1)
visualize_feature_differences(train_blurred[random_idx], train_sharp[random_idx], model, device)

"""# **NAFNET**"""

#Model's structure is constructed with great assistance from ChatGPT, and Gemini helped fix a few errors along the way
from pytorch_msssim import ssim  #Structural similarity index module for perceptual loss
import torch    #PyTorch core library
import torch.nn as nn   #Building blocks for neural network construction
import torch.nn.functional as F   #Functional interface for neural network layers
from torch.utils.data import Dataset, DataLoader  #Dataset handling and batching
import torchvision.models as models   #Pretrained models
import torchvision.transforms as transforms #Preprocessing image transforms
import os, cv2, random #File system, OpenCV, randomness and numerical operations
import numpy as np  #NumPy library
import matplotlib.pyplot as plt   #Plotting library
from tqdm import tqdm   #Progress bar for loops
from torch.optim.lr_scheduler import ReduceLROnPlateau  #Learning rate scheduler

#Custom 2D layer normalization
class LayerNorm2d(nn.Module):
    def __init__(self, num_features, eps=1e-6):
        super().__init__()  #Base class constructor
        self.weight = nn.Parameter(torch.ones(1, num_features, 1, 1))   #Initializes weights for 2D layer
        self.bias = nn.Parameter(torch.zeros(1, num_features, 1, 1))  #Initializes biases for 2D layer
        self.eps = eps  #To avoid division by 0

    def forward(self, x):
        mean = x.mean(dim=(2, 3), keepdim=True)  #Computes mean across spatial dimensions for each channel
        var = x.var(dim=(2, 3), keepdim=True, unbiased=False)   #Computes variance across spatial dimensions for each channel
        return (x - mean) / torch.sqrt(var + self.eps) * self.weight + self.bias    #Returns normalized input after applying learned scale and bias

#Simple Channel Attention module
class SimpleChannelAttention(nn.Module):
    def __init__(self, channels):
        super().__init__()
        self.pool = nn.AdaptiveAvgPool2d(1)  #Average pooling to get channel descriptors
        #Two 1x1 convolutions with GELU activation to compute channel weights
        self.conv = nn.Sequential(
            nn.Conv2d(channels, channels, 1, padding=0),
            nn.GELU(),
            nn.Conv2d(channels, channels, 1, padding=0),
        )

    def forward(self, x):
        y = self.pool(x)  #Reduces dimensions (HxW) for each channel to 1x1
        y = self.conv(y)  #Attention weights
        y = x * y #Scales inputs by the attention map
        return y

#NAFBlock: Basic building block for NAFNet with depth-wise convolution and feed-forward architecture
class NAFBlock(nn.Module):
    def __init__(self, c, DW_Expand=2, FFN_Expand=2):
        super().__init__()
        #Expanded channel counts
        dw_channels = c * DW_Expand
        ffn_channels = c * FFN_Expand

        #First sub-block: 2D Layer Normalization is applied, 1x1 convolution is done, 3x3 depth-wise convolution applied,
        #1x1 convolution done again, and simple channel attention is done
        self.norm1 = LayerNorm2d(c)  #Standardizes each channel/feature map
        self.conv1 = nn.Conv2d(c, dw_channels, 1, 1, 0)  #Reduces number of channels to "dw_channels"
        self.dwconv = nn.Conv2d(dw_channels, dw_channels, 3, 1, 1, groups=dw_channels)  #Picks up spatial patterns within each channel
        self.conv2 = nn.Conv2d(dw_channels, c, 1, 1, 0) #Restores original channel's dimensions
        self.sca = SimpleChannelAttention(c)  #Decides which channels are most important and scales accordingly

        #Second sub-block: 2D Layer normalization is applied and then "MLP" applied to each pixel
        self.norm2 = LayerNorm2d(c)   #Normalizes each channel
        #Projects to higher dimension, then uses nonlinear activation to introduce complexity and then projects back down
        self.ffn = nn.Sequential(
            nn.Conv2d(c, ffn_channels, 1, 1, 0),
            nn.GELU(),
            nn.Conv2d(ffn_channels, c, 1, 1, 0)
        )
        #Learnable scaling factors for the residual connections, both intialized at 0
        self.beta = nn.Parameter(torch.zeros((1, c, 1, 1)), requires_grad=True)
        self.gamma = nn.Parameter(torch.zeros((1, c, 1, 1)), requires_grad=True)

    def forward(self, x):
        y = self.norm1(x)  #Normalizes each channel of x
        y = self.conv1(y)   #Pointwise convolution, expands to higher dimension
        y = self.dwconv(y)    #Depthwise convolution
        y = self.conv2(y)   #Pointwise convolution, projects back down
        y = self.sca(y)  #Simple channel attention
        x = x + y * self.beta   #Adds first residual
        y = self.norm2(x)   #Normalizes the second branch
        y = self.ffn(y)   #Feed forward MLP
        x = x + y * self.gamma  #Adds second residual
        return x

#NAFNet implementation with full encoder-decoder deblurring model
class NAFNet(nn.Module):
    def __init__(self, img_channels=3, width=32, enc_blks=[1, 1, 2, 6], dec_blks=[1, 1, 1, 1], middle_blk_num=10):
        super().__init__()
        self.intro = nn.Conv2d(img_channels, width, 3, 1, 1) #Convolution to map RGB to the feature space of size "width"
        #Builds encoder stages: progressively downsamples and processes
        self.encoders = nn.ModuleList()
        self.downs = nn.ModuleList()  #Downsampling between stages

        for i, blocks in enumerate(enc_blks):
            #Creates a sequence of "blocks" NAFBlocks
            encoder = nn.Sequential(
                *[NAFBlock(width * (2 ** i)) for _ in range(blocks)]
            )
            #Adds a downsampling convolution if it's not the last stage, halves height and width
            self.encoders.append(encoder)
            if i < len(enc_blks) - 1:
                self.downs.append(nn.Conv2d(width * (2 ** i), width * (2 ** (i+1)), 2, 2, 0))

        #Middle blocks: heavy processing at smallest spatial resolution
        self.middle_blks = nn.Sequential(
            *[NAFBlock(width * (2 ** (len(enc_blks) - 1))) for _ in range(middle_blk_num)]
        )

        #Builds decoder stages: upsamples and merges skip connections
        self.decoders = nn.ModuleList()
        self.ups = nn.ModuleList()  #For upsampling

        for i, blocks in enumerate(dec_blks):
            #Creates a sequence of "blocks" NAFBlocks
            decoder = nn.Sequential(
                *[NAFBlock(width * (2 ** (len(dec_blks) - i - 1))) for _ in range(blocks)]
            )
            self.decoders.append(decoder)
            #Adds upsampling convolution if not last stage
            if i < len(dec_blks) - 1:
                self.ups.append(nn.ConvTranspose2d( width * (2 ** (len(dec_blks) - i - 1)),
                    width * (2 ** (len(dec_blks) - i - 2)), 2, 2, 0))

        #Output convolution: maps features back to RGB image
        self.outro = nn.Conv2d(width, img_channels, 3, 1, 1)

    def forward(self, x):
        #Initial feature extraction
        features = self.intro(x)

        #Encoder path with skip connections
        encs = []
        for i, encoder in enumerate(self.encoders):
            features = encoder(features)  #Applies NAFBlocks
            encs.append(features)  #Saves feeatures
            if i < len(self.encoders) - 1:
                features = self.downs[i](features) #Downsamples spatial dimensions

        #Middle blocks: bottleneck processing at smallest resolution
        features = self.middle_blks(features)

        #Decoder path: upsamples and skips connections
        for i, decoder in enumerate(self.decoders):
            if i > 0:
                features = self.ups[i-1](features)  #Upsamples to larger scale
                features = features + encs[len(encs) - i - 1] #Retieves corresponding encoder features
            features = decoder(features)  #Processes features with NAFBlocks

        output = self.outro(features)   #Maps back to RGB from feature space
        output = output + x    #Residual connection from input to output (helps with training stability)
        return output

#GOPRO Dataset class
class DeblurDataset(Dataset):
    def __init__(self, blur_paths, sharp_paths, transform=None, crop_size=256):
        self.blur_paths = blur_paths    #List of filepaths for blurred images
        self.sharp_paths = sharp_paths  #List of filepaths for sharp images
        self.transform = transform or get_transform() #Preprocessing pipeline
        self.crop_size = crop_size

    def __len__(self):
        return len(self.blur_paths)   #Total number of samples

    def __getitem__(self, idx):
        #Reads blurred and sharp images
        blur = cv2.cvtColor(cv2.imread(self.blur_paths[idx]), cv2.COLOR_BGR2RGB)    #Converts blurred images to RGB format
        sharp = cv2.cvtColor(cv2.imread(self.sharp_paths[idx]), cv2.COLOR_BGR2RGB)  #Converts sharp images to RGB format
        #Random horizontal flipping for augmentation, 50% chance
        if random.random() < 0.5:
            blur = cv2.flip(blur, 1)
            sharp = cv2.flip(sharp, 1)

        #Random crop for training
        if self.crop_size:
            h, w = blur.shape[:2]  #Image dimensions
            if h > self.crop_size and w > self.crop_size:  #If image is larger than crop size, random crop is taken
                top = random.randint(0, h - self.crop_size)
                left = random.randint(0, w - self.crop_size)
                blur = blur[top:top+self.crop_size, left:left+self.crop_size]
                sharp = sharp[top:top+self.crop_size, left:left+self.crop_size]
            else:  #Otherwise, image is resized to ensure consistent input size
                blur = cv2.resize(blur, (self.crop_size, self.crop_size))
                sharp = cv2.resize(sharp, (self.crop_size, self.crop_size))

        #Converts images to tensors and normalizes to [-1,1]
        blur = self.transform(blur)
        sharp = self.transform(sharp)
        return blur, sharp  #Returns tuple of tensors to feed into model

#Image transforms
def get_transform():  #Converts images to tensors and normalizes
    #Composes multiple transforms with mean of 0.5 and range from [-1,1]
    return transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])  #Normalizes to [-1, 1]
    ])

#Denormalization: converts tensor back to image
def denormalize(tensor):
    return (tensor * 0.5 + 0.5).clamp(0, 1)  #Maps tensor back to [0,1] by scaling by 0.5 and shifting by 0.5

#Charbonnier Loss
class CharbonnierLoss(nn.Module):  #L1-like loss that is robust to outliers
    def __init__(self, eps=1e-6):
        super().__init__()
        self.eps = eps    #Small constant to avoid sqrt of 0

    def forward(self, x, y):  #Charbonnier loss between 2 tensors
        diff = x - y  #Element-wise difference between tensors
        loss = torch.mean(torch.sqrt(diff * diff + self.eps))  #Loss is computed as the mean of sqrt(d^2 +eps)
        return loss

#Edge Loss
class EdgeLoss(nn.Module):  #L! loss on edges by applying Laplacian filter
    def __init__(self, device):
        super().__init__()
        ##x3 Laplacian kernel to detect edges, expanded for 3 channels
        kernel = torch.tensor([[-1, -1, -1],
                               [-1,  8, -1],
                               [-1, -1, -1]], dtype=torch.float32).expand(3, 1, 3, 3)
        self.lap = nn.Conv2d(3, 3, 3, padding=1, bias=False, groups=3)
        self.lap.weight.data = kernel  #Sets kernel weights
        self.lap.weight.requires_grad = False  #Does not update during training
        self.device = device  #Device used is saved

    def forward(self, x, y):
        self.lap = self.lap.to(self.device)  #Ensures kernel is on device
        return F.l1_loss(self.lap(x), self.lap(y))  #Applies filter and computes L1 loss between images

#Deblur Loss: Improved loss function combining many losses
class DeblurLoss(nn.Module): #Combines Charbonnier, Edge, L1, and SSIM losses
    def __init__(self, device, alpha=1.0, beta=0.2, gamma=0.05, eps=1e-6):
        super().__init__()
        self.device = device
        self.charb = CharbonnierLoss(eps=eps)  #Charbonnier Loss
        self.l1 = nn.L1Loss()  #L1 loss
        self.edge = EdgeLoss(device) #Edge loss
        self.alpha, self.beta, self.gamma = alpha, beta, gamma  #Weights for different losses, adjustable

    def forward(self, out, tgt):
        #out, tgt in [-1,1] range and Charbonnier loss computed
        loss_charb = self.charb(out, tgt)

        #Rescales into [0,1] for SSIM and L1 losses
        out01 = (out  + 1) * 0.5
        tgt01 = (tgt  + 1) * 0.5
        #Computes SSIM loss, returning similarity
        loss_ssim = 1 - ssim(
            out01, tgt01,
            data_range=1.0,
        )
        loss_edge = self.edge(out01, tgt01) #COmputes Edge loss
        loss_l1   = self.l1(out01, tgt01) #Computes L1 loss
        return (
          self.alpha * loss_charb
        + self.beta  * loss_ssim
        + self.gamma * loss_edge
        + loss_l1 * 0.05
      )   #Returns weighted sum of different loss components as final deblurring loss

#PSNR calculation
def compute_psnr(a, b):  #Computes PSNR between 2 tensors in -1 to 1 range
    a01 = (a + 1) * 0.5  #Maps to [0,1]
    b01 = (b + 1) * 0.5  #Maps to [0,1]
    mse = torch.mean((a01 - b01)**2)  #Mean squared error
    return 20 * torch.log10(1.0 / torch.sqrt(mse))   #Computes and returns PSNR


#Training loop
def train_model(model, train_loader, val_loader, optimizer, device, epochs=10):
    model.train()  #Sets model to training mode
    loss_fn = DeblurLoss(device)   #Initializes loss
    #scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=1e-6)  #Scheduler gradually reduced learning rate

    for epoch in range(epochs):  #Loops over all epochs
        total_loss = 0
        for blur, sharp in tqdm(train_loader, desc=f"Epoch {epoch+1}/{epochs}"):  #Loops over all training batches
            blur, sharp = blur.to(device), sharp.to(device)   #Moves data to device being used
            optimizer.zero_grad()   #Resets gradients
            output = model(blur)    #Forward pass of model
            loss = loss_fn(output, sharp)   #Computes loss
            loss.backward() #Backpropagation of model
            optimizer.step()   #Updates weights
            total_loss += loss.item()   #Accumulates loss

        avg_loss = total_loss / len(train_loader)  #Average training loss
        #scheduler.step()  #Updates learning rate
        model.eval()  #Switches model to evaluation mode for computing PSNR on validation set
        total_psnr = 0.0
        n_val = len(val_loader)
        with torch.no_grad():  #Disables gradient calculation
            for bl, sh in val_loader:
                bl, sh = bl.to(device), sh.to(device)
                pred = model(bl).clamp(-1,1)  #Ensures outputs are in -1 to 1 range
                total_psnr += compute_psnr(pred, sh)  #Sums up PSNR values
        avg_psnr = total_psnr / n_val  #Computes average PSNR for validation set
        current_lr = optimizer.param_groups[0]['lr']  #Current learning rate
        print(
            f"Train Loss: {avg_loss:.4f}  "
            f"Avg PSNR: {avg_psnr:.2f}Â dB  "
            f"LR: {current_lr:.2e}"
        )  #Outputs results for epoch
        model.train()  #Sets model back to training mode

#Tests and visualizes results
def test_model(model, test_loader, device, save_path=None, num_samples=5):
    model.eval()  #Sets model to evaluation mode, disables batch normalization updates
    fig = plt.figure(figsize=(25, 4 * num_samples))  #Creates figure

    #Selects random unique indices from test set
    indices = random.sample(range(len(test_loader.dataset)), k=num_samples)

    for i, idx in enumerate(indices):  #Loops over chosen samples
        blur, sharp = test_loader.dataset[idx]    #Obtains raw tensor values
        blur = blur.unsqueeze(0).to(device)  #Adds batch dimensions and moves to device
        sharp = sharp.unsqueeze(0).to(device)

        with torch.no_grad():  #Disables gradient calculation
            output = model(blur)  #Forward pass of model

        #Denormalizes for visualization and converts to numpy images
        blur_img = denormalize(blur[0]).permute(1, 2, 0).cpu().numpy()
        sharp_img = denormalize(sharp[0]).permute(1, 2, 0).cpu().numpy()
        output_img = denormalize(output[0]).permute(1, 2, 0).cpu().numpy()
        #Scales to 0 to 1 range
        output01 = (output + 1) * 0.5
        blur01   = (blur   + 1) * 0.5
        sharp01  = (sharp  + 1) * 0.5

        diff_db = (output01 - blur01).abs()[0]  #Computes difference between NAFNET output and blurred image
        diff_gt = (sharp01 - blur01).abs()[0]  #Computes difference sharp image and blurred image

        diff_db_norm = diff_db / (diff_db.max().item() or 1e-6)   #Normalizes NAFNET differences
        diff_gt_norm = diff_gt / (diff_gt.max().item() or 1e-6)   #Normalizes sharp differences

        res_db = diff_db_norm.permute(1,2,0).cpu().numpy()  #Rearranges dimensions of tensor
        res_gt = diff_gt_norm.permute(1,2,0).cpu().numpy()  #Rearranges dimensions of tensor

        #Computes PSNR
        mse = np.mean((output_img - sharp_img) ** 2)
        psnr = 20 * np.log10(1.0 / np.sqrt(mse))
        #Plots blurred image
        plt.subplot(num_samples, 5, i*5+1)
        plt.imshow(blur_img)
        plt.title("Blurred")
        plt.axis('off')
        #Plots deblurred NAFNET image
        plt.subplot(num_samples, 5, i*5+2)
        plt.imshow(output_img)
        plt.title(f"Deblurred (PSNR: {psnr:.2f}dB)")
        plt.axis('off')
        #Plots sharp image
        plt.subplot(num_samples, 5, i*5+3)
        plt.imshow(sharp_img)
        plt.title("Ground Truth")
        plt.axis('off')
        #Plots comparison between original and NAFNET
        plt.subplot(num_samples, 5, i*5+4)
        plt.imshow(res_db, cmap='magma')
        plt.title("Residual: NAFNET vs Original")
        plt.axis("off")
        #Plots comparison between sharp and blurred
        plt.subplot(num_samples, 5, i*5+5)
        plt.imshow(res_gt, cmap='magma')
        plt.title("Residual: Sharp vs Original")
        plt.axis("off")

    plt.tight_layout()
    if save_path:
        plt.savefig(save_path)
    plt.show()
    return fig

#Runs deblur pipeline
def run_deblur_pipeline(train_blurred, val_blurred, val_sharp, train_sharp, test_blurred, test_sharp, epochs=10):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")  #Selects device
    print(f"Using device: {device}")  #Outputs used device to user

    val_ds   = DeblurDataset(val_blurred, val_sharp,     crop_size=None)  #Validation dataset without cropping
    train_dataset = DeblurDataset(train_blurred, train_sharp, crop_size=256)  #Training dataset with random cropping
    test_dataset = DeblurDataset(test_blurred, test_sharp, crop_size=None)   #Testing dataset with no cropping

    #Creates data loaders with appropriate batch sizes
    train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)  #Shuffles for training data
    val_loader   = DataLoader(val_ds,   batch_size=1, shuffle=False)
    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)

    #Initializes improved NAFNet model
    model = NAFNet(
        img_channels=3,
        width=32,  #Base channel count
        enc_blks=[1, 1, 2, 6],  #Encoder blocks at each scale
        dec_blks=[2, 2, 2, 2],  #Decoder blocks at each scale
        middle_blk_num=10  #Middle blocks
    ).to(device)

    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=1e-4)    #Uses AdamW optimizer with weight decay
    train_model(model, train_loader, val_loader, optimizer, device, epochs=epochs)    #Trains the model
    test_model(model, test_loader, device, save_path="nafnet_results.png", num_samples=5)    #Tests the model and visualize results
    torch.save(model.state_dict(), "nafnet_deblur_model.pth")    #Saves the trained model
    return model

#Collects image filepaths
def get_image_paths(directory):
    blur_paths = []  #Blurred image paths
    sharp_paths = [] #Sharp image paths
    #Finds all images in the directory
    for root, _, files in os.walk(directory):
        for file in files:  #Iterates over each file in directory
            if file.lower().endswith(('.png', '.jpg', '.jpeg')):  #Finds image extension
                if 'blur' in root.lower() or 'blur' in file.lower():
                    blur_paths.append(os.path.join(root, file))  #Adds blurred image filepath
                elif 'sharp' in root.lower() or 'sharp' in file.lower() or 'gt' in file.lower():
                    sharp_paths.append(os.path.join(root, file))  #Adds sharp image filepath

    #Sorts paths to ensure matching pairs
    blur_paths.sort()
    sharp_paths.sort()
    return blur_paths, sharp_paths

#Runs code
if __name__ == "__main__":
    max_train = 500  #Size of training dataset
    train_blurred = train_blurred[:max_train]  #Selects subset of blurred images
    train_sharp = train_sharp[:max_train]   #Selects subset of sharp images
    val_blurred = train_blurred[-50:]  #Splits off certain blurred images for validation
    val_sharp   = train_sharp  [-50:]  #Splits off certain sharp images for validation

    #Runs the pipeline
    model = run_deblur_pipeline(
        train_blurred,
        val_blurred,
        val_sharp,
        train_sharp,
        test_blurred,
        test_sharp,
        epochs=10
    )